import os

import requests
import soundfile as sf
from aiogram import Bot
from aiogram.types import Message
from core.config.settings import settings
from core.config.settings import Emoji
import speech_recognition as sr
import json
import re
from vosk import KaldiRecognizer
import wave
import subprocess
from pydub import AudioSegment
import asyncio

# –£–∫–∞–∑—ã–≤–∞–µ–º –ø—É—Ç—å –∫ ffmpeg –¥–ª—è pydub
AudioSegment.converter = r"C:\ProgramData\chocolatey\bin\ffmpeg.exe"

async def save_voice_to_file(bot: Bot, message: Message, file_path: str) -> str:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø—É—Ç—å"""
    voice = message.voice
    voice_file_info = await bot.get_file(voice.file_id)
    await bot.download_file(voice_file_info.file_path, file_path)
    return file_path


async def voice_to_text_whisper(file_path: str) -> str:
    """–ü—Ä–∏–Ω–∏–º–∞–µ—Ç –ø—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Ñ–∞–π–ª–∞."""
    if not settings.bots.whisper:
        raise ValueError("Whisper model is not initialized")
        
    segments, _ = settings.bots.whisper.transcribe(file_path, language="ru", beam_size=5)
    segments = list(segments)  # The transcription will actually run here.
    result = []
    for segment in segments:
        result.append(segment.text)

    return ' '.join(result)


async def voice_to_text_google(file_path: str) -> str:
    """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ Google Speech Recognition"""
    try:
        wav_path = file_path.replace('.ogg', '.wav')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        if not convert_to_wav(file_path, wav_path):
            print("Failed to convert audio for Google recognition")
            return ""
        
        # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ç–µ–∫—Å—Ç
        recognizer = settings.bots.google_model
        with sr.AudioFile(wav_path) as source:
            audio = recognizer.record(source)
            text = recognizer.recognize_google(audio, language='ru-RU')
        
        return text
    except Exception as e:
        print(f"Google recognition error: {e}")
        return ""


async def voice_to_text_vosk(file_path: str) -> str:
    """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ Vosk"""
    try:
        wav_path = file_path.replace('.ogg', '.wav')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        if not convert_to_wav(file_path, wav_path):
            print("Failed to convert audio for Vosk recognition")
            return ""
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª
        wf = wave.open(wav_path, "rb")
        
        # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å
        model = settings.bots.vosk_model
        rec = KaldiRecognizer(model, wf.getframerate())
        rec.SetWords(True)
        
        # –ß–∏—Ç–∞–µ–º –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ–º –∞—É–¥–∏–æ
        result = ""
        while True:
            data = wf.readframes(4000)
            if len(data) == 0:
                break
            if rec.AcceptWaveform(data):
                result += json.loads(rec.Result())["text"] + " "
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
        final_result = json.loads(rec.FinalResult())
        result += final_result["text"]
        
        return result.strip()
    except Exception as e:
        print(f"Vosk recognition error: {e}")
        return ""


def convert_to_wav(input_path: str, output_path: str, sample_rate: int = 16000) -> bool:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è ogg –≤ wav —á–µ—Ä–µ–∑ pydub
    """
    try:
        if not os.path.exists(input_path):
            print(f"Input file not found: {input_path}")
            print(f"Current working directory: {os.getcwd()}")
            print(f"Absolute path to input file: {os.path.abspath(input_path)}")
            return False
            
        print(f"Converting {input_path} to {output_path}")
        print(f"File exists: {os.path.exists(input_path)}")
        print(f"File size: {os.path.getsize(input_path)} bytes")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º OGG —Ñ–∞–π–ª
        audio = AudioSegment.from_ogg(input_path)
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω—É–∂–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        audio = audio.set_frame_rate(sample_rate).set_channels(1)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ WAV
        audio.export(output_path, format="wav")
        
        if os.path.exists(output_path):
            print(f"Successfully converted {input_path} to {output_path}")
            print(f"Output file size: {os.path.getsize(output_path)} bytes")
            return True
        return False
        
    except Exception as e:
        print(f"Conversion error: {e}")
        print(f"Error type: {type(e)}")
        import traceback
        print(f"Traceback: {traceback.format_exc()}")
        return False


async def text_to_sentence(text: str) -> [str]:
    return re.findall('[–ê-–Ø][^–ê-–Ø]*', text)


def get_sentiment_emoji(sentiment):
    """–§—É–Ω–∫—Ü–∏—è —Å–æ–æ—Ç–Ω–µ—Å–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–π —ç–º–æ—Ü–∏–∏ —Å —Å–º–∞–π–ª–∏–∫–æ–º –∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
    return Emoji.emoji_mapping.get(sentiment, "")


async def markup_text_emotional(text: str) -> str:
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏ –∏—Ö —Å–º–∞–π–ª–∏–∫–∞–º–∏"""


async def convert_to_wav_pydub(input_path: str, output_path: str) -> bool:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è ogg –≤ wav —á–µ—Ä–µ–∑ pydub"""
    try:
        audio = AudioSegment.from_ogg(input_path)
        audio = audio.set_frame_rate(16000).set_channels(1)
        audio.export(output_path, format="wav")
        return True
    except Exception as e:
        print(f"Pydub conversion error: {e}")
        return False


async def process_voice_recognition(temp_file: str):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤—Å–µ–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
    results = []
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ wav –¥–ª—è –¥—Ä—É–≥–∏—Ö —Å–∏—Å—Ç–µ–º
    wav_file = temp_file.replace('.ogg', '.wav')
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º ffmpeg –Ω–∞–ø—Ä—è–º—É—é –≤–º–µ—Å—Ç–æ pydub
    try:
        process = subprocess.Popen([
            'ffmpeg',
            '-loglevel', 'quiet',
            '-i', temp_file,
            '-ar', '16000',
            '-ac', '1',
            '-f', 'wav',
            wav_file
        ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        
        stdout, stderr = process.communicate()
        conversion_success = process.returncode == 0 and os.path.exists(wav_file)
        
        if not conversion_success:
            print(f"FFmpeg conversion failed: {stderr.decode() if stderr else 'No error output'}")
    except Exception as e:
        print(f"Conversion error: {e}")
        conversion_success = False
    
    if conversion_success:
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∏—Å—Ç–µ–º—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = [
            voice_to_text_google(wav_file),
            voice_to_text_vosk(wav_file)
        ]
        other_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for result, system in zip(other_results, ["üéØ Google Speech", "üìù Vosk"]):
            if isinstance(result, Exception):
                results.append((system, f"–û—à–∏–±–∫–∞: {str(result)}"))
            else:
                results.append((system, result))
    else:
        results.extend([
            ("üéØ Google Speech", "–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ"),
            ("üìù Vosk", "–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ")
        ])
    
    return results
